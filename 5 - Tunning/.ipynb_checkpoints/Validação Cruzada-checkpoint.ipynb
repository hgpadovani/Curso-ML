{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada\n",
    "\n",
    "Validação cruzada é um método de treinamento utilizado para explorar seu modelo e seus dados, e o quão suceptível à overfitting ele é. Consiste em um método de validação onde divide-se o modelo em alguns subsets de dados, treinando e validando de forma cruzada, e avaliando métricas.\n",
    "\n",
    "- K-Fold e Stratified K-fold\n",
    "\n",
    "Consiste em dividir seu dataset em K pastas, treinando em (K-1) pastas e validando na K-ésima pasta. Esse processo é repetido K vezes, alternando sempre a pasta de validação. A versão Stratified tenta manter uma proporção do mesmo número de elementos por classe em cada um dos folds.\n",
    "\n",
    "- Leave-One-Out (LOO)\n",
    "\n",
    "Semelante ao método K-Fold. Para um dataset de n amostras, treina-se em (n-1) amostras e valida-se na n-ésima amostra. Esse processo é repetido n vezes, sempre alterando a amostra de validação. É mais custoso que o K-Fold, porque treina n modelos, porém é mais efetivo em relação à métricas, porque treina com mais dados por modelo.\n",
    "\n",
    "- Leave-P-Out (LPO)\n",
    "\n",
    "Semelhante ao método LOO, porém pode-se definir o número p de amostras para validação.\n",
    "\n",
    "- ShuffleSplit e Stratified ShuffleSplit\n",
    "\n",
    "Semelhante ao K-Fold, porém as amostras serão embaralhadas antes da divisão entre os folds. A versão Stratified tenta manter a proporção de classes ao longo do folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as libs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o dataset\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, [2, 3]]\n",
    "y = dataset.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um classificador\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando cada um dos métodos descritos no início da sessão\n",
    "### K-Fold e Stratified K-Fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits = 10, random_state = 0)\n",
    "acc = []\n",
    "for train, test in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "acc_mean = np.array(acc).mean()\n",
    "acc_std = np.array(acc).std()\n",
    "\n",
    "print(\"As acurácias foram:\")\n",
    "print(acc)\n",
    "print()\n",
    "print(\"O valor médio e desvio foi de: {:0.2f} +/- {:0.2f}\".format(acc_mean, acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 0)\n",
    "acc = []\n",
    "for train, test in skf.split(X, y):\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "acc_mean = np.array(acc).mean()\n",
    "acc_std = np.array(acc).std()\n",
    "\n",
    "print(\"As acurácias foram:\")\n",
    "print(acc)\n",
    "print()\n",
    "print(\"O valor médio e desvio foi de: {:0.2f} +/- {:0.2f}\".format(acc_mean, acc_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "acc = []\n",
    "for train, test in loo.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "acc_mean = np.array(acc).mean()\n",
    "\n",
    "print(\"As acurácias foram:\")\n",
    "print(acc)\n",
    "print()\n",
    "print(\"O valor médio foi de: {:0.2f}\".format(acc_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle Split e Stratified Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits = 10, random_state = 0, test_size=0.25)\n",
    "acc = []\n",
    "for train, test in ss.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "acc_mean = np.array(acc).mean()\n",
    "acc_std = np.array(acc).std()\n",
    "\n",
    "print(\"As acurácias foram:\")\n",
    "print(acc)\n",
    "print()\n",
    "print(\"O valor médio e desvio foi de: {:0.2f} +/- {:0.2f}\".format(acc_mean, acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = 10, random_state = 0, test_size = 0.25)\n",
    "acc = []\n",
    "for train, test in sss.split(X, y):\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "acc_mean = np.array(acc).mean()\n",
    "acc_std = np.array(acc).std()\n",
    "\n",
    "print(\"As acurácias foram:\")\n",
    "print(acc)\n",
    "print()\n",
    "print(\"O valor médio e desvio foi de: {:0.2f} +/- {:0.2f}\".format(acc_mean, acc_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por último, uma demonstração de um helper que já retorna as métricas de validação por K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dividindo em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando um método de validação\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, scoring = 'accuracy')\n",
    "acc_mean = accuracies.mean()\n",
    "acc_std = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"As acurácias foram:\")\n",
    "print(accuracies)\n",
    "print()\n",
    "print(\"O valor médio e desvio foi de: {:0.2f} +/- {:0.2f}\".format(acc_mean, acc_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
